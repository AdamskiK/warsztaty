{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Podstawy - propagacja wsteczna, metoda gradientu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stwórzmy jakiś zbiór, którego nie da się łatwo \"uchwycić\" metodami liniowymi. Najprostszym pomysłem są okręgi o różnych promieniach, i klasie zależnej od promienia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "points_per_class = 200\n",
    "X = np.zeros((points_per_class*n_classes, 2))\n",
    "Y = np.zeros(points_per_class*n_classes, dtype=int)\n",
    "for i in range(n_classes):\n",
    "    idx = range(points_per_class*i,points_per_class*(i+1))\n",
    "    \n",
    "    r = i + np.random.random(points_per_class)* 0.5 # \n",
    "    t = np.random.random(points_per_class) *2* np.pi\n",
    "    \n",
    "    X[idx] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "    Y[idx] = int(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwszą próbę klasyfikacji zrobimy za pomocą prostego klasyfikatora liniowego, to znaczy bezpośrednio po warstwie wejściowej mamy 3-elementową warstwę wyjściową reprezentującą prawdopobieństwo przynależności do danej klasy.\n",
    "\n",
    "Postać macierzowa:\n",
    "$$ y = f(U),$$\n",
    "$$ U = XW +b $$\n",
    "\n",
    "gdzie $f$ jest funkcją softmax:,\n",
    "\n",
    "$$ \\hat{y_j} = \\sigma (u)_j = \\frac{\\exp{u_j}}{\\sum_{j = 1}^{k} \\exp{u_j}} $$\n",
    "\n",
    "dla $j = 1, ..., k$.\n",
    "\n",
    "Będziemy optymalizować funkcję straty \n",
    "$$ L(y, \\hat{y}) = -\\frac{1}{N} \\sum_{n} y_n\\log{\\hat{y_n}}  $$\n",
    "\n",
    "Przydatna rzecz: \n",
    "$$ \\frac{\\partial L}{\\partial u_j} = \\hat{y_j} - y_j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randomizacja wartości początkowych\n",
    "D = 2\n",
    "K = 3\n",
    "W = 1 * np.random.randn(D,K)\n",
    "b = np.zeros((1,K))\n",
    "\n",
    "# parametry \n",
    "step_size = 1e-2\n",
    "reg = 1e-4\n",
    "\n",
    "num_examples = X.shape[0]\n",
    "\n",
    "for i in range(200):  \n",
    "    # obliczamy scory oraz przynależności do klas przy aktualnych wagach\n",
    "    \n",
    "    \n",
    "\n",
    "    # obliczamy funkcję straty dla aktualnej predykcji\n",
    "    \n",
    "    \n",
    "\n",
    "    # wyliczamy gradient funkcji straty\n",
    "    \n",
    "    \n",
    "    \n",
    "    # it's backpropagation time!\n",
    "    \n",
    "    \n",
    "\n",
    "    # dodajemy wpływ regularyzacji do gradientu wag\n",
    "    \n",
    "\n",
    "    # aktualizujemy parametry\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predykcja - postępujemy tak, jak na początku kroku uczenia\n",
    "scores = np.dot(X, W) + b\n",
    "predicted_class = np.argmax(scores, axis=1) # nie musimy wyliczać konkretnych prawdopodobienstw - exp jest funkcją rosnącą\n",
    "print('overall accuracy: %.2f' % (np.mean(predicted_class == Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=predicted_class, s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Klasyfikator z warstwą ukrytą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# POKAZAĆ co się dzieje przy dodaniu wag początkowych na 0\n",
    "# randomizacja wartości początkowych\n",
    "D = 2\n",
    "K = 3\n",
    "h = 12 # size of hidden layer\n",
    "W = 1 * np.random.randn(D,h) #np.zeros((D,K)) \n",
    "b = np.zeros((1,h))\n",
    "W2 = 1 * np.random.randn(h,K) #np.zeros((D,K)) \n",
    "b2 = np.zeros((1,K))\n",
    "\n",
    "# parametry \n",
    "step_size = 1e-0\n",
    "reg = 5e-2 # regularization strength\n",
    "\n",
    "\n",
    "num_examples = X.shape[0]\n",
    "for i in range(30):  \n",
    "    # obliczamy scory oraz przynależności do klas przy aktualnych wagach\n",
    "    \n",
    "\n",
    "    # obliczamy funkcję straty dla aktualnej predykcji\n",
    "    \n",
    "\n",
    "    # wyliczamy gradient funkcji straty\n",
    "   \n",
    "\n",
    "    # wsteczna propagacja gradientu\n",
    "    # najpierw badamy wpływ wag i stałej w ostatniej warstwie\n",
    "       \n",
    "    # następnie liczymy gradient dla wartości w warstwie ukrytej\n",
    "    \n",
    "    # pamietamy o uwzględnieniu pochodnej funkcji aktywacyjnej - na szczęście jest dość prosta\n",
    "    \n",
    "    # na koniec dostajemy gradienty dla pierwszej warstwy\n",
    "   \n",
    "\n",
    "    # dodajemy jeszcze wpływ regularyzacji do gradientu wag    \n",
    "\n",
    "    # aktualizujemy parametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_layer = np.maximum(0, np.dot(X, W) + b)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print('training accuracy: %.2f' % (np.mean(predicted_class == Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=predicted_class, s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, Flatten\n",
    "from keras.optimizers import SGD, adam\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Kręgi w zbożu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw zbudujemy sieci analogiczne do poprzednich - dzięki temu zobaczymy jak działają podstawowe funkcje i klasy, oraz przekonamy się jak bardzo user-friendly jest keras ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na pierwszy ogień - model liniowy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. budowanie modelu - dodawanie kolejnych warstw\n",
    "model_linear = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. kompilacja modelu - określenie algorytmu optymalizacji, oraz funkcji straty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. 'fit' - czyli uczymy model na danych treningowych \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_linear = model_linear.predict(X)\n",
    "print('training accuracy: %.2f' % (np.mean(np.argmax(preds_linear, axis=1) == Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie model z jedną warstwą ukrytą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "model_2l = Sequential()\n",
    "\n",
    "# 2.\n",
    "\n",
    "# 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_2l = model_2l.predict(X)\n",
    "print('training accuracy: %.2f' % (np.mean(np.argmax(preds_2l, axis=1) == Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bostońskie domostwa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_boston, Y_train_boston), (X_test_boston, Y_tes_boston) = boston_housing.load_data()\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "model_boston_linear = Sequential()\n",
    "\n",
    "# 2.\n",
    "\n",
    "# 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def describe_column(col):\n",
    "    return( (np.min(col), np.max(col), np.mean(col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = np.apply_along_axis(describe_column, 0, X_train_boston)\n",
    "stats.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_boston /= stats[1]\n",
    "X_test_boston /= stats[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "model_boston_linear = Sequential()\n",
    "\n",
    "# 2.\n",
    "\n",
    "# 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# obliczenie funkcji straty na zbiorze testowym\n",
    "np.mean((model_boston_linear.predict(X_test_boston).reshape(Y_test.shape_boston) - Y_test_boston)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1.\n",
    "model_boston_2l = Sequential()\n",
    "\n",
    "# 2.\n",
    "\n",
    "# 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# obliczenie funkcji straty na zbiorze testowym\n",
    "np.mean((model_boston_2l.predict(X_test_boston).reshape(Y_test_boston.shape) - Y_test_boston)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rozpoznawanie pisma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train_mnist, Y_train_mnist), (X_test_mnist, Y_test_mnist) = mnist.load_data()\n",
    "print(X_train_mnist.shape)\n",
    "print(Y_train_mnist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digit = X_train_mnist[0]\n",
    "plt.imshow(digit, interpolation = \"nearest\", cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.\n",
    "model_boston_2l = Sequential()\n",
    "\n",
    "# 2.\n",
    "\n",
    "# 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_mnist = model_mnist.predict(X_test_mnist)\n",
    "print('test accuracy: %.2f' % (np.mean(np.argmax(preds_mnist, axis=1) == Y_test_mnist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
